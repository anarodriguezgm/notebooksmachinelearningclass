{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500,)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estandarizamos los valores de las variables explicativas para la regresión \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler  =  StandardScaler ()\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*...*</font>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de la Regresión Logística -->  0.6427\n",
      "F1 Score de la Regresión Logística -->  0.6324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear',C=1e9)\n",
    "logreg.fit(X_train_s, y_train)  ## standar features\n",
    "y_pred_log = logreg.predict(X_test_s) \n",
    "\n",
    "acc_log=accuracy_score(y_test,y_pred_log)\n",
    "f1_log=f1_score(y_test,y_pred_log,average='binary')\n",
    "\n",
    "print('Accuracy de la Regresión Logística -->  '+ str(round(acc_log,4)))\n",
    "print('F1 Score de la Regresión Logística -->  '+ str(round(f1_log,4)))\n",
    "##np.sqrt(metrics.mean_squared_error(y_test, y_pred_log))     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Arbol -->  0.6453\n",
      "F1 Score del Arbol -->  0.6088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treereg = DecisionTreeClassifier(max_leaf_nodes=6,random_state=1)\n",
    "treereg.fit(X_train, y_train)  ## Aquí no necesitamos las variables estandarizadas\n",
    "y_pred_tree = treereg.predict(X_test)\n",
    "\n",
    "acc_tree=accuracy_score(y_test,y_pred_tree)\n",
    "f1_tree=f1_score(y_test,y_pred_tree,average='binary')\n",
    "\n",
    "print('Accuracy del Arbol -->  '+ str(round(acc_tree,4)))\n",
    "print('F1 Score del Arbol -->  '+ str(round(f1_tree,4)))\n",
    "##np.sqrt(metrics.mean_squared_error(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*100 Decision Trees where max_depth=None*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "treesA = {}\n",
    "for i in range(n_estimators):\n",
    "    treesA[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    treesA[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*100 Decision Trees where max_depth=2*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "treesB = {}\n",
    "for i in range(n_estimators):\n",
    "    treesB[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=2, random_state=seeds[i])\n",
    "    treesB[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*100 Logistic Regressions*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "n_samples = X_train_s.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]\n",
    "\n",
    "logreg = {}\n",
    "for i in range(n_estimators):\n",
    "    logreg[i] = LogisticRegression(solver='liblinear',C=1e9, random_state=seeds[i])\n",
    "    logreg[i].fit(X_train_s[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_pred_dftA = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_dftA.iloc[:, i] = treesA[i].predict(X_test)\n",
    "    \n",
    "y_pred_dftB = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_dftB.iloc[:, i] = treesB[i].predict(X_test) \n",
    "    \n",
    "y_pred_dflr = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_dflr.iloc[:, i] = logreg[i].predict(X_test_s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*Ensemble using majority voting*</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predAB=pd.merge(y_pred_dftA,y_pred_dftB,left_index=True,right_index=True,suffixes=['_1','_2'])\n",
    "\n",
    "y_pred_union=pd.merge(y_predAB,y_pred_dflr,left_index=True,right_index=True)\n",
    "\n",
    "y_pred = (y_pred_union.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2_1</th>\n",
       "      <th>3_1</th>\n",
       "      <th>4_1</th>\n",
       "      <th>5_1</th>\n",
       "      <th>6_1</th>\n",
       "      <th>7_1</th>\n",
       "      <th>8_1</th>\n",
       "      <th>9_1</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0_1  1_1  2_1  3_1  4_1  5_1  6_1  7_1  8_1  9_1 ...  90  91  92  93  \\\n",
       "1483    0    0    1    0    1    0    1    1    0    1 ...   1   1   1   1   \n",
       "2185    1    1    1    1    0    1    1    1    1    1 ...   1   1   1   1   \n",
       "2520    1    0    1    1    1    0    0    1    0    0 ...   1   1   0   1   \n",
       "3721    0    1    1    1    1    1    1    1    0    1 ...   1   1   0   1   \n",
       "3727    0    0    0    0    0    0    0    0    0    1 ...   0   0   1   0   \n",
       "\n",
       "      94  95  96  97  98  99  \n",
       "1483   1   1   1   1   0   1  \n",
       "2185   1   1   1   1   1   1  \n",
       "2520   1   1   1   1   1   1  \n",
       "3721   1   1   1   1   1   1  \n",
       "3727   0   0   0   1   0   0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.612"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127344521224088"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*F1 Score of Ensemble*  es mucho más alto que los modelos individuales donde tenemos un 0.71 respecto a 0.63 con la regresión logistica y 0.60 con el árbol de desición vistos en el literal 9.1</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[196 548]\n",
      " [ 34 722]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix : \\n', cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive predictive value :  0.26344086021505375\n"
     ]
    }
   ],
   "source": [
    "ppv = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Positive predictive value : ', ppv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_union.sum(axis=1) >= (n_estimators /1.21)).astype(np.int)  ## probab de 83%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7160493827160493"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_oob = []\n",
    "# show the \"out-of-bag\" observations for each sample\n",
    "for sample in samples:\n",
    "    samples_oob.append(sorted(set(range(n_samples)) - set(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsA = np.zeros(n_estimators)\n",
    "errorsB = np.zeros(n_estimators)\n",
    "errorsC = np.zeros(n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    y_pred_A = treesA[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errorsA[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_A)    \n",
    "for i in range(n_estimators):\n",
    "    y_pred_B = treesB[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errorsB[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_B)\n",
    "for i in range(n_estimators):\n",
    "    y_pred_C = logreg[i].predict(X_train_s[samples_oob[i]])\n",
    "    errorsC[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorsAB=np.concatenate((errorsA, errorsB), axis=0)\n",
    "errorsABC=np.concatenate((errorsAB, errorsC), axis=0)\n",
    "errorsABC.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = (1 - errorsABC) / (1 - errorsABC).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum_1 = ((y_pred_union) * alpha).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6440677966101696, 0.65)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (weighted_sum_1 >= 0.5).astype(np.int)\n",
    "\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=blue>*F1 score Ensemble using weighted voting*  es un valor ponderado de presición similar a scores de  los modelos individuales donde tenemos un 0.64 respecto a 0.63 con la regresión logistica y 0.60 con el árbol de desición vistos en el literal 9.1.  Lo cual podemos concluir que el metodo de Emsemble por Majority Voting tiene una mejor precisión que éste</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[500 244]\n",
      " [281 475]]\n"
     ]
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix : \\n', cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive predictive value :  0.6720430107526881\n"
     ]
    }
   ],
   "source": [
    "ppv = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Positive predictive value : ', ppv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7062245491564864, 0.6633333333333333)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (weighted_sum_1 >= 0.3).astype(np.int)\n",
    "\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=blue>*Se puede optimizar el promedio ponderado de predicción definiendo si es popular con una probabilidad mayor o igual al 30%*</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))\n",
    "X_train_B = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))\n",
    "X_train_C = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    X_train_A[i] = treesA[i].predict(X_train)\n",
    "for i in range(n_estimators):\n",
    "    X_train_B[i] = treesB[i].predict(X_train)\n",
    "for i in range(n_estimators):\n",
    "    X_train_C[i] = logreg[i].predict(X_train_s)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainAB=pd.merge(X_train_A,X_train_B,left_index=True,right_index=True,suffixes=['_A','_B'])\n",
    "\n",
    "X_trainABC=pd.merge(X_trainAB,X_train_C,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(cv = 5 )\n",
    "lr.fit(X_trainABC, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.88400337e-02,  8.00938280e-02,  7.62552730e-02,\n",
       "         7.70977945e-02,  7.90558749e-02,  7.93311121e-02,\n",
       "         7.84321717e-02,  7.67497056e-02,  7.60445235e-02,\n",
       "         8.28988217e-02,  8.16919525e-02,  7.75584439e-02,\n",
       "         7.92876328e-02,  8.01168080e-02,  7.93111168e-02,\n",
       "         8.25181276e-02,  7.59993134e-02,  7.80886274e-02,\n",
       "         7.65773663e-02,  7.81528748e-02,  7.64226794e-02,\n",
       "         7.76006913e-02,  7.83947730e-02,  7.66466206e-02,\n",
       "         7.67567831e-02,  7.81062028e-02,  7.53140145e-02,\n",
       "         7.72464384e-02,  7.81985125e-02,  7.95990533e-02,\n",
       "         7.67537561e-02,  7.87156803e-02,  8.03977766e-02,\n",
       "         7.55864337e-02,  8.09508661e-02,  7.87388148e-02,\n",
       "         7.59043419e-02,  8.02054123e-02,  7.42430463e-02,\n",
       "         7.55946390e-02,  7.63833083e-02,  7.68329927e-02,\n",
       "         7.75378749e-02,  8.00933492e-02,  7.88870685e-02,\n",
       "         7.92941826e-02,  7.90668882e-02,  7.77710646e-02,\n",
       "         7.74043723e-02,  8.10909501e-02,  7.74637654e-02,\n",
       "         7.68941869e-02,  7.54943567e-02,  7.98352520e-02,\n",
       "         7.91380343e-02,  7.80496910e-02,  7.71296651e-02,\n",
       "         8.07693428e-02,  7.58498702e-02,  7.67538740e-02,\n",
       "         7.90380272e-02,  7.71148670e-02,  7.56028159e-02,\n",
       "         7.74444574e-02,  7.97380937e-02,  7.85763905e-02,\n",
       "         7.93336378e-02,  7.99294937e-02,  7.85737600e-02,\n",
       "         7.58761253e-02,  7.66941840e-02,  7.83629194e-02,\n",
       "         7.80780798e-02,  7.78419316e-02,  7.73727964e-02,\n",
       "         8.01575695e-02,  7.82840918e-02,  7.98510109e-02,\n",
       "         7.67105573e-02,  7.98596694e-02,  7.81926365e-02,\n",
       "         7.92907463e-02,  7.70860716e-02,  7.51300471e-02,\n",
       "         7.67989790e-02,  7.81222363e-02,  7.93001927e-02,\n",
       "         7.72028110e-02,  7.72824766e-02,  7.97363933e-02,\n",
       "         7.93721735e-02,  7.59843183e-02,  8.31970732e-02,\n",
       "         8.07852388e-02,  8.12231779e-02,  7.88135443e-02,\n",
       "         7.76281153e-02,  8.03182200e-02,  7.64755994e-02,\n",
       "         7.90830310e-02,  1.19524329e-03, -1.70593947e-03,\n",
       "        -1.51876412e-03,  1.25468976e-04, -1.15223569e-04,\n",
       "        -7.79970496e-04, -1.23533856e-04,  2.79343338e-04,\n",
       "        -1.32162632e-04, -1.67966277e-03, -1.87364822e-03,\n",
       "        -1.30297147e-03, -1.51929717e-03, -1.96635274e-03,\n",
       "        -4.43147841e-04, -3.12637849e-03,  4.35322836e-04,\n",
       "         1.53066864e-03, -2.47984552e-03,  9.65306637e-04,\n",
       "         1.15816960e-03, -2.26595037e-03,  1.59396865e-03,\n",
       "        -2.42351275e-03, -1.42788154e-03, -2.29752016e-03,\n",
       "         1.99333156e-03, -1.98293188e-03,  3.71392487e-03,\n",
       "        -1.28727613e-03, -7.03816805e-04, -2.40491398e-03,\n",
       "        -2.54137678e-04,  6.71475293e-04,  2.87075527e-03,\n",
       "        -1.98293188e-03, -7.17593429e-04, -2.86823908e-03,\n",
       "         4.50593751e-04, -9.28203208e-05, -3.69524070e-04,\n",
       "        -1.09766474e-03, -1.67761027e-03,  3.47528526e-04,\n",
       "         1.65934236e-03, -1.17936182e-03, -6.72688147e-04,\n",
       "        -2.48990898e-04, -1.96983182e-03,  5.86176568e-04,\n",
       "        -2.30698464e-04, -1.90449603e-03,  9.67998850e-04,\n",
       "        -2.45937164e-03, -2.51973426e-03, -7.60782508e-04,\n",
       "        -1.73519758e-03, -1.89872652e-04,  3.69142312e-03,\n",
       "        -6.02198300e-04, -4.05552752e-04, -1.37662924e-03,\n",
       "        -1.37967604e-03,  1.20187816e-04, -2.39663150e-03,\n",
       "        -1.59896275e-03, -5.57381382e-04, -1.57227767e-03,\n",
       "        -1.39652787e-03,  2.49613258e-03, -1.85266046e-03,\n",
       "         6.00221320e-04, -1.37662924e-03,  3.41294704e-04,\n",
       "         9.67527090e-04,  7.75618090e-04, -1.47101214e-03,\n",
       "        -3.03376021e-04,  3.21404311e-03, -7.65150227e-04,\n",
       "         1.65032889e-03, -2.39965736e-05, -1.89002068e-03,\n",
       "        -1.19615620e-03,  1.80908263e-03, -2.15274280e-03,\n",
       "        -1.07383172e-03, -1.60212378e-04,  1.86992201e-03,\n",
       "         1.15857095e-03, -2.58695216e-03,  8.33054077e-04,\n",
       "        -2.02031391e-03, -6.16415327e-04,  1.30422785e-03,\n",
       "        -1.98293188e-03, -1.51710081e-03,  1.24495792e-03,\n",
       "         1.11501777e-03, -2.09664950e-03,  1.31277264e-03,\n",
       "         1.71374581e-03, -4.47860475e-04,  3.63031329e-04,\n",
       "         3.03042477e-03,  2.35742754e-03,  1.59809018e-03,\n",
       "         1.84588059e-03,  1.23376548e-03,  9.38100786e-04,\n",
       "         1.30305246e-03,  2.47863502e-03,  8.42392218e-04,\n",
       "         1.83248525e-03,  7.35005917e-04,  1.72587296e-03,\n",
       "         3.01852882e-03,  1.13888800e-03,  1.38416962e-03,\n",
       "        -4.67303628e-04,  3.61111007e-03,  1.88850748e-03,\n",
       "         8.52329381e-04, -4.48985658e-04,  2.10909242e-03,\n",
       "         1.02149714e-03, -1.97894619e-04,  1.29712855e-03,\n",
       "         2.10196860e-03,  6.39287286e-04, -2.05762343e-04,\n",
       "         1.20314721e-03,  2.33086533e-03,  1.00461644e-03,\n",
       "         1.46586015e-03,  3.01859227e-03,  9.15461907e-04,\n",
       "         2.29603458e-03,  1.07072931e-03,  1.21259575e-03,\n",
       "         1.21243726e-03,  2.05055750e-03,  7.05551886e-04,\n",
       "         1.07039683e-03, -3.30950378e-05,  3.69230635e-03,\n",
       "         1.37304117e-03, -2.84205732e-04,  2.09954509e-03,\n",
       "         2.91845414e-03,  3.78449516e-03,  1.23132913e-03,\n",
       "         1.42047130e-03,  1.03338569e-03,  1.33738943e-03,\n",
       "         2.18070135e-03,  2.38420342e-03,  2.35059073e-04,\n",
       "         1.46542141e-04,  1.48589229e-03,  2.49698227e-03,\n",
       "         1.30690277e-03,  1.97239004e-04,  1.65233084e-03,\n",
       "         1.77832422e-03,  4.10872936e-04,  1.23116312e-03,\n",
       "         2.62235912e-03,  1.71377260e-03,  1.41441904e-03,\n",
       "        -2.90522438e-04,  2.96471801e-03,  2.71655567e-03,\n",
       "         1.86916771e-03,  1.61718777e-03,  1.11615438e-03,\n",
       "         1.99378192e-03,  3.62192991e-04,  1.80547812e-03,\n",
       "         2.31714963e-04,  2.91873437e-03,  2.07713814e-03,\n",
       "         2.53356620e-03,  1.02478423e-03,  1.12346467e-03,\n",
       "         4.71149278e-03,  1.84994524e-03,  1.22906362e-03,\n",
       "         2.26265999e-03,  2.35746574e-03,  2.23424095e-03,\n",
       "         2.19260391e-03,  2.48080138e-03,  2.59263565e-03,\n",
       "         8.20357331e-04,  1.88045946e-03,  1.76464779e-04,\n",
       "        -6.55330568e-04,  2.60532241e-03,  1.56187445e-03]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(y_pred_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6582947785855915, 0.6553333333333333)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=blue>*F1 score Ensemble using Stacking*  este valor también es similar a scores de  los modelos individuales donde tenemos un 0.65 respecto a 0.63 con la regresión logistica y 0.60 con el árbol de desición vistos en el literal 9.1.  Lo cual podemos concluir que el metodo de Emsemble por Stacking dada la propabilidad por defecto de>= 0.5 para que sea popular, no es el mejor porque el valor ponderado de la precisión no se optimiza en gran escala.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (lr.predict_proba(y_pred_union)[:,1]>=0.27).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7094379639448568, 0.6346666666666667)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_pred_p, y_test), metrics.accuracy_score(y_pred_p, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>*F1 score with Ensemble using Stacking, mejora cuando se reduce la probabilidad para definir la popularidad en mayor o igual a un 27%*</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por: Ana Milena Rodríguez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
